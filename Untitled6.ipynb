{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2foprbfslANt"
   },
   "source": [
    "#Content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uDg7HUbRlCol"
   },
   "source": [
    "1.Image classification for 3 digits numbers built with MNIST dataset digits.\n",
    "\n",
    "2.Adding numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "srtWIsYYyAbe"
   },
   "source": [
    "#Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DeAiwkWvyEpt"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import cv2\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from imgaug import augmenters as iaa\n",
    "from tensorflow.keras import datasets\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense, RepeatVector\n",
    "from keras.layers import LSTM, RNN, SimpleRNN\n",
    "\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "from keras.models import load_model\n",
    "\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "06vdX_PTlaUd"
   },
   "source": [
    "#Image classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "w4ep8l51yQ89"
   },
   "source": [
    "##Dataset generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WF64Vx7Gx8Rf"
   },
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = datasets.mnist.load_data()\n",
    "\n",
    "def sometimes(aug): return iaa.Sometimes(0.5, aug)\n",
    "\n",
    "seq = iaa.Sequential([\n",
    "    iaa.Affine(\n",
    "        scale={\"x\": (0.8, 1), \"y\": (0.8, 1)},\n",
    "        translate_percent={\"x\": (-0.1, 0.1), \"y\": (-0.1, 0.1)},\n",
    "        rotate=(-15, 15),\n",
    "        shear=(-5, 5),\n",
    "        cval=(0, 0),\n",
    "        mode='constant'\n",
    "    )\n",
    "])\n",
    "\n",
    "\n",
    "def crop_number(number):\n",
    "    \"\"\"\n",
    "        Crops a MNIST digit to its containing bounding box with some random noise.\n",
    "    \"\"\"\n",
    "    vsum = np.sum(number, axis=0)\n",
    "    vsum[vsum > 0] = 1\n",
    "    vdif = np.diff(vsum)\n",
    "    vdif[vdif > 0] = 1\n",
    "    xs = np.argwhere(vdif > 0).ravel()\n",
    "\n",
    "    random_cut1 = np.random.randint(-1, 3)\n",
    "    random_cut2 = np.random.randint(-1, 3)\n",
    "\n",
    "    try:\n",
    "        cropped_number = number[0:28, xs[0] - random_cut1:xs[1] + random_cut2]\n",
    "        if cropped_number.shape[1] < 6:\n",
    "            raise Exception\n",
    "    except:\n",
    "        cropped_number = number\n",
    "\n",
    "    return cropped_number\n",
    "\n",
    "\n",
    "def pad_image(number, target_shape=(28, 84)):\n",
    "    \"\"\"\n",
    "        Makes all images the same shape\n",
    "    \"\"\"\n",
    "    _shape = number.shape\n",
    "\n",
    "    height_pad = (-_shape[0] + target_shape[0]) // 2\n",
    "    width_pad = (-_shape[1] + target_shape[1]) // 2\n",
    "\n",
    "    padded = cv2.copyMakeBorder(number,\n",
    "                                height_pad,\n",
    "                                height_pad,\n",
    "                                width_pad + int(_shape[1] % 2 == 1),\n",
    "                                width_pad,\n",
    "                                cv2.BORDER_CONSTANT,\n",
    "                                value=0)\n",
    "    return padded\n",
    "\n",
    "\n",
    "def generate_images(data_x, data_y, batch_size, length=255):\n",
    "    \"\"\"\n",
    "        Generates images containing numbers from MNIST with random translations.\n",
    "    \"\"\"\n",
    "\n",
    "    while True:\n",
    "\n",
    "        x_batch = []\n",
    "        y_numbers_batch = []\n",
    "        y_results = []\n",
    "\n",
    "        for _ in range(batch_size):\n",
    "            x = [np.zeros((28, 0)), np.zeros((28, 0))]\n",
    "            y_numbers = []\n",
    "\n",
    "            for num in range(2):\n",
    "                random_num = random.randrange(length)\n",
    "                decimal = str(random_num)\n",
    "\n",
    "                y_numbers.append(np.array([random_num]))\n",
    "\n",
    "                for digit in decimal:\n",
    "                    numbers = np.argwhere(data_y == int(digit))\n",
    "\n",
    "                    loc = np.random.choice(numbers.ravel(), 1)\n",
    "                    number = np.squeeze(data_x[loc])\n",
    "                    augmented_number = seq.augment_images([number])[0]\n",
    "                    cropped_number = crop_number(augmented_number)\n",
    "\n",
    "                    x[num] = np.hstack((x[num], cropped_number))\n",
    "                x[num] = pad_image(x[num])\n",
    "\n",
    "            x_batch.append(x)\n",
    "            y_numbers_batch.append(y_numbers)\n",
    "            y_results.append(y_numbers[-1] + y_numbers[-2])\n",
    "\n",
    "        yield np.array(x_batch), np.squeeze(np.array(y_numbers_batch)), np.array(y_results)\n",
    "\n",
    "\n",
    "def training_generator(batch_size=32):\n",
    "    \"\"\"\n",
    "        Use this function to generate training samples. Images are generated using the training set of MNIST.\n",
    "        Example usage:\n",
    "\n",
    "        generator = training_generator(batch_size=8) # batch size of 8\n",
    "\n",
    "        x, numbers, numbers_sum = next(generator)\n",
    "\n",
    "        # x.shape == (8, 2, 28, 84)     # 8 pairs of images with height 28px and width 84px\n",
    "        # numbers.shape == (8, 2)       # 8 pairs of numbers corresponding to the images\n",
    "        # numbers_sum.shape == (8, 1)   # 8 numbers that represent the sum of the numbers from the images\n",
    "\n",
    "    \"\"\"\n",
    "    return generate_images(x_train, y_train, batch_size)\n",
    "\n",
    "\n",
    "def test_generator(batch_size=32):\n",
    "    \"\"\"\n",
    "        Use this function to generate test samples. Images are generated using the test set of MNIST.\n",
    "        Example usage:\n",
    "\n",
    "        generator = test_generator(batch_size=8) # batch size of 8\n",
    "\n",
    "        x, numbers, numbers_sum = next(generator)\n",
    "\n",
    "        # x.shape == (8, 2, 28, 84)     # 8 pairs of images with height 28px and width 84px\n",
    "        # numbers.shape == (8, 2)       # 8 pairs of numbers corresponding to the images\n",
    "        # numbers_sum.shape == (8, 1)   # 8 numbers that represent the sum of the numbers from the images\n",
    "\n",
    "    \"\"\"\n",
    "    return generate_images(x_test, y_test, batch_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sK4Hob-8GKgp"
   },
   "source": [
    "##Generate the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tdCHKEwiGI8o"
   },
   "outputs": [],
   "source": [
    "generator = training_generator(30000)\n",
    "train_x, numbers_train, numbers_sum_train = next(generator)\n",
    "\n",
    "generator = test_generator(1000)\n",
    "test_x, numbers_test, numbers_sum_test = next(generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1YCKwe_HRw0t"
   },
   "source": [
    "Normalize the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hj5lPgHOeirB"
   },
   "outputs": [],
   "source": [
    "train_x = train_x[:,0]\n",
    "train_x = tf.keras.utils.normalize(train_x)\n",
    "train_y = numbers_train[:,0]\n",
    "\n",
    "test_x = test_x[:,0]\n",
    "test_x = tf.keras.utils.normalize(test_x)\n",
    "test_y = numbers_test[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "a-Qyhjp9oELz"
   },
   "source": [
    "Expand the arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o0B4u5iKUwqv"
   },
   "outputs": [],
   "source": [
    "\n",
    "train_x = np.expand_dims(train_x,axis=3)\n",
    "test_x = np.expand_dims(test_x, axis=3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "u_9DlsEHxoOl"
   },
   "source": [
    "##Data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 198
    },
    "colab_type": "code",
    "id": "PkjhgrGdxnqx",
    "outputId": "b94f3622-93f3-49be-e97d-74068221c956"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAd8AAAC1CAYAAAAeGPXQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\njOVdllSPjwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe5c63f50b8>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(train_x[0], cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wOCC3Sz5ywjM"
   },
   "source": [
    "The dataset has 20000 samples and each sample is a 28x84 matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "nLHzcRACy2s6",
    "outputId": "7aa335ba-bc53-4823-9826-7f4d06a0a124"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 28, 84)"
      ]
     },
     "execution_count": 14,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "d5btxmHlzXzi"
   },
   "source": [
    "Each value in the matrix is between 0-255(0-1 after normalization) representing the intensity of the pixel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 274
    },
    "colab_type": "code",
    "id": "rxNwDo6lyjtf",
    "outputId": "9e777382-eeeb-41ef-a0b6-618476e4771d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.14659083 0.46071404 0.61777565\n",
      " 0.60730487 0.12564928 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.        ]\n"
     ]
    }
   ],
   "source": [
    "print(train_x[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_WNr0w-4xhyG"
   },
   "source": [
    "##Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Fj5qKxa9oH30"
   },
   "outputs": [],
   "source": [
    "def create_model():\n",
    "  \n",
    "  model = Sequential()\n",
    "  model.add(Conv2D(35, (2, 2), input_shape=(28,84,1)))\n",
    "  model.add(Activation('relu'))\n",
    "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "  model.add(Conv2D(35, (2, 2)))\n",
    "  model.add(Activation('relu'))\n",
    "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "  # the model so far outputs 3D feature maps (height, width, features)\n",
    "\n",
    "  model.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
    "  model.add(Dense(255))\n",
    "  model.add(Activation('relu'))\n",
    "  model.add(Dropout(0.5))\n",
    "  model.add(Dense(255))\n",
    "  model.add(Activation('softmax'))\n",
    "\n",
    "  model.compile(loss='sparse_categorical_crossentropy',\n",
    "                optimizer='adam',\n",
    "                metrics=['accuracy'])\n",
    "  \n",
    "  return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "e0m7sm280w4B"
   },
   "source": [
    "##Tunning the hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3GxAtF7XSFSL"
   },
   "source": [
    "Summarize results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Dr5Zax9vSC30"
   },
   "outputs": [],
   "source": [
    "def summarize_results(grid_result):\n",
    "  print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "  means = grid_result.cv_results_['mean_test_score']\n",
    "  stds = grid_result.cv_results_['std_test_score']\n",
    "  params = grid_result.cv_results_['params']\n",
    "  for mean, stdev, param in zip(means, stds, params):\n",
    "      print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jg_ZsMZ0R2Od"
   },
   "source": [
    "Use a smaller dataset so the script will run faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4AzbPhf0H-nr"
   },
   "outputs": [],
   "source": [
    "train_xx = train_x[0:300]\n",
    "train_yy = train_y[0:300]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2genqN6rSAGD"
   },
   "source": [
    "Number of epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "t7mVZJ2V1C1X"
   },
   "outputs": [],
   "source": [
    "np.random.seed(7)\n",
    "\n",
    "# create the model\n",
    "model = KerasClassifier(build_fn=create_model, verbose=0)\n",
    "\n",
    "# define the grid search parameters\n",
    "epochs = [5, 7, 10, 13, 16]\n",
    "param_grid = dict(epochs=epochs)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3, verbose=10)\n",
    "grid_result = grid.fit(train_xx, train_yy)\n",
    "\n",
    "summarize_results(grid_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ECljvZE9SQ6Q"
   },
   "source": [
    "Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 350
    },
    "colab_type": "code",
    "id": "bYsuxYcWSUIM",
    "outputId": "f48b9fe1-43b4-4493-f415-5cec14c054c6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 7 candidates, totalling 21 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:   17.7s\n",
      "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:   39.6s\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=-1)]: Done  21 out of  21 | elapsed:  4.4min finished\n",
      "[Parallel(n_jobs=-1)]: Done  21 out of  21 | elapsed:  4.4min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.050000 using {'epochs': 13, 'optimizer': 'Nadam'}\n",
      "0.003333 (0.004714) with: {'epochs': 13, 'optimizer': 'SGD'}\n",
      "0.043333 (0.020548) with: {'epochs': 13, 'optimizer': 'RMSprop'}\n",
      "0.030000 (0.016330) with: {'epochs': 13, 'optimizer': 'Adagrad'}\n",
      "0.023333 (0.012472) with: {'epochs': 13, 'optimizer': 'Adadelta'}\n",
      "0.040000 (0.016330) with: {'epochs': 13, 'optimizer': 'Adam'}\n",
      "0.046667 (0.024944) with: {'epochs': 13, 'optimizer': 'Adamax'}\n",
      "0.050000 (0.024495) with: {'epochs': 13, 'optimizer': 'Nadam'}\n"
     ]
    }
   ],
   "source": [
    "def create_model(optimizer):\n",
    "  \n",
    "  model = Sequential()\n",
    "  model.add(Conv2D(35, (2, 2), input_shape=(28,84,1)))\n",
    "  model.add(Activation('relu'))\n",
    "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "  # the model so far outputs 3D feature maps (height, width, features)\n",
    "\n",
    "  model.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
    "  model.add(Dense(255))\n",
    "  model.add(Activation('relu'))\n",
    "  model.add(Dropout(0.5))\n",
    "  model.add(Dense(255))\n",
    "  model.add(Activation('softmax'))\n",
    "\n",
    "  model.compile(loss='sparse_categorical_crossentropy',\n",
    "                optimizer=optimizer,\n",
    "                metrics=['accuracy'])\n",
    "  \n",
    "  return model\n",
    "\n",
    "# create the model\n",
    "model = KerasClassifier(build_fn=create_model, epochs=10, verbose=0)\n",
    "\n",
    "# define the grid search parameters\n",
    "optimizer = ['SGD', 'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Adamax', 'Nadam']\n",
    "param_grid = dict(optimizer=optimizer, epochs=[13])\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3, verbose=10)\n",
    "grid_result = grid.fit(train_xx, train_yy)\n",
    "\n",
    "summarize_results(grid_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DB9NskXBmToK"
   },
   "source": [
    "Kernel initializer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 384
    },
    "colab_type": "code",
    "id": "FN3WEpVRiyCE",
    "outputId": "617b80c1-068b-4e31-f1ad-c84f213b6baa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:   22.3s\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:   48.7s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=-1)]: Done  21 tasks      | elapsed:  4.4min\n",
      "[Parallel(n_jobs=-1)]: Done  24 out of  24 | elapsed:  4.8min remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  24 out of  24 | elapsed:  4.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.053333 using {'init_mode': 'glorot_normal'}\n",
      "0.030000 (0.014142) with: {'init_mode': 'uniform'}\n",
      "0.040000 (0.014142) with: {'init_mode': 'lecun_uniform'}\n",
      "0.050000 (0.021602) with: {'init_mode': 'normal'}\n",
      "0.010000 (0.008165) with: {'init_mode': 'zero'}\n",
      "0.053333 (0.018856) with: {'init_mode': 'glorot_normal'}\n",
      "0.050000 (0.008165) with: {'init_mode': 'glorot_uniform'}\n",
      "0.043333 (0.016997) with: {'init_mode': 'he_normal'}\n",
      "0.036667 (0.016997) with: {'init_mode': 'he_uniform'}\n"
     ]
    }
   ],
   "source": [
    "def create_model(init_mode):\n",
    "  \n",
    "  model = Sequential()\n",
    "  model.add(Conv2D(35, (2, 2), input_shape=(28,84,1)))\n",
    "  model.add(Activation('relu'))\n",
    "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "  # the model so far outputs 3D feature maps (height, width, features)\n",
    "\n",
    "  model.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
    "  model.add(Dense(255, kernel_initializer=init_mode))\n",
    "  model.add(Activation('relu'))\n",
    "  model.add(Dropout(0.5))\n",
    "  model.add(Dense(255, kernel_initializer=init_mode))\n",
    "  model.add(Activation('softmax'))\n",
    "\n",
    "  model.compile(loss='sparse_categorical_crossentropy',\n",
    "                optimizer='nadam',\n",
    "                metrics=['accuracy'])\n",
    "  \n",
    "  return model\n",
    "\n",
    "# create the model\n",
    "model = KerasClassifier(build_fn=create_model, epochs=13, verbose=0)\n",
    "\n",
    "# define the grid search parameters\n",
    "init_mode = ['uniform', 'lecun_uniform', 'normal', 'zero', 'glorot_normal', 'glorot_uniform', 'he_normal', 'he_uniform']\n",
    "param_grid = dict(init_mode=init_mode)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3, verbose=10)\n",
    "grid_result = grid.fit(train_xx, train_yy)\n",
    "\n",
    "summarize_results(grid_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kzkYkiaqmWmK"
   },
   "source": [
    "Layer activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 384
    },
    "colab_type": "code",
    "id": "vFhwMvSnl5Z0",
    "outputId": "25dce6c8-0dbb-4cbf-8b89-a0454e6d203c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:  1.9min\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:  4.0min\n",
      "[Parallel(n_jobs=-1)]: Done  21 tasks      | elapsed:  5.3min\n",
      "[Parallel(n_jobs=-1)]: Done  24 out of  24 | elapsed:  5.9min remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  24 out of  24 | elapsed:  5.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.043333 using {'activation': 'tanh'}\n",
      "0.013333 (0.009428) with: {'activation': 'softmax'}\n",
      "0.016667 (0.012472) with: {'activation': 'softplus'}\n",
      "0.040000 (0.008165) with: {'activation': 'softsign'}\n",
      "0.040000 (0.016330) with: {'activation': 'relu'}\n",
      "0.043333 (0.012472) with: {'activation': 'tanh'}\n",
      "0.006667 (0.009428) with: {'activation': 'sigmoid'}\n",
      "0.010000 (0.008165) with: {'activation': 'hard_sigmoid'}\n",
      "0.036667 (0.004714) with: {'activation': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "def create_model(activation):\n",
    "  \n",
    "  model = Sequential()\n",
    "  model.add(Conv2D(35, (2, 2), input_shape=(28,84,1)))\n",
    "  model.add(Activation(activation))\n",
    "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "  # the model so far outputs 3D feature maps (height, width, features)\n",
    "\n",
    "  model.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
    "  model.add(Dense(255, kernel_initializer='glorot_normal'))\n",
    "  model.add(Activation(activation))\n",
    "  model.add(Dropout(0.5))\n",
    "  model.add(Dense(255, kernel_initializer='glorot_normal'))\n",
    "  model.add(Activation('softmax'))\n",
    "\n",
    "  model.compile(loss='sparse_categorical_crossentropy',\n",
    "                optimizer='nadam',\n",
    "                metrics=['accuracy'])\n",
    "  \n",
    "  return model\n",
    "\n",
    "# create the model\n",
    "model = KerasClassifier(build_fn=create_model, epochs=13, verbose=0)\n",
    "\n",
    "# define the grid search parameters\n",
    "activation = ['softmax', 'softplus', 'softsign', 'relu', 'tanh', 'sigmoid', 'hard_sigmoid', 'linear']\n",
    "param_grid = dict(activation=activation)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3, verbose=10)\n",
    "grid_result = grid.fit(train_xx, train_yy)\n",
    "\n",
    "summarize_results(grid_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 402
    },
    "colab_type": "code",
    "id": "16uyDUwnoJSc",
    "outputId": "3bd77d80-b086-4e5f-c73c-d40d9b1c97e3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:   22.1s\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:   49.3s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=-1)]: Done  21 tasks      | elapsed:  4.4min\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:  6.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.050000 using {'dropout_rate': 0.4}\n",
      "0.040000 (0.024495) with: {'dropout_rate': 0.0}\n",
      "0.033333 (0.016997) with: {'dropout_rate': 0.1}\n",
      "0.033333 (0.012472) with: {'dropout_rate': 0.2}\n",
      "0.036667 (0.012472) with: {'dropout_rate': 0.3}\n",
      "0.050000 (0.016330) with: {'dropout_rate': 0.4}\n",
      "0.043333 (0.016997) with: {'dropout_rate': 0.5}\n",
      "0.043333 (0.026247) with: {'dropout_rate': 0.6}\n",
      "0.050000 (0.024495) with: {'dropout_rate': 0.7}\n",
      "0.043333 (0.028674) with: {'dropout_rate': 0.8}\n",
      "0.030000 (0.016330) with: {'dropout_rate': 0.9}\n"
     ]
    }
   ],
   "source": [
    "def create_model(dropout_rate):\n",
    "  \n",
    "  model = Sequential()\n",
    "  model.add(Conv2D(35, (2, 2), input_shape=(28,84,1)))\n",
    "  model.add(Activation('tanh'))\n",
    "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "  # the model so far outputs 3D feature maps (height, width, features)\n",
    "\n",
    "  model.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
    "  model.add(Dense(255, kernel_initializer='glorot_normal'))\n",
    "  model.add(Activation('tanh'))\n",
    "  model.add(Dropout(dropout_rate))\n",
    "  model.add(Dense(255, kernel_initializer='glorot_normal'))\n",
    "  model.add(Activation('softmax'))\n",
    "\n",
    "  model.compile(loss='sparse_categorical_crossentropy',\n",
    "                optimizer='nadam',\n",
    "                metrics=['accuracy'])\n",
    "  \n",
    "  return model\n",
    "\n",
    "# create the model\n",
    "model = KerasClassifier(build_fn=create_model, epochs=13, verbose=0)\n",
    "\n",
    "# define the grid search parameters\n",
    "dropout_rate = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "param_grid = dict(dropout_rate=dropout_rate)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3, verbose=10)\n",
    "grid_result = grid.fit(train_xx, train_yy)\n",
    "\n",
    "summarize_results(grid_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "d7rIkcSkwNd9"
   },
   "source": [
    "Filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 280
    },
    "colab_type": "code",
    "id": "reukBYMeqwCy",
    "outputId": "33816421-2939-4549-b762-5665483706b3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    7.2s\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:   23.1s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:  2.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.050000 using {'filters': 30}\n",
      "0.046667 (0.012472) with: {'filters': 10}\n",
      "0.046667 (0.020548) with: {'filters': 20}\n",
      "0.050000 (0.032660) with: {'filters': 30}\n",
      "0.036667 (0.024944) with: {'filters': 40}\n",
      "0.046667 (0.012472) with: {'filters': 50}\n"
     ]
    }
   ],
   "source": [
    "def create_model(filters):\n",
    "  \n",
    "  model = Sequential()\n",
    "  model.add(Conv2D(filters, (2, 2), input_shape=(28,84,1)))\n",
    "  model.add(Activation('tanh'))\n",
    "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "  # the model so far outputs 3D feature maps (height, width, features)\n",
    "\n",
    "  model.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
    "  model.add(Dense(255, kernel_initializer='glorot_normal'))\n",
    "  model.add(Activation('tanh'))\n",
    "  model.add(Dropout(0.4))\n",
    "  model.add(Dense(255, kernel_initializer='glorot_normal'))\n",
    "  model.add(Activation('softmax'))\n",
    "\n",
    "  model.compile(loss='sparse_categorical_crossentropy',\n",
    "                optimizer='nadam',\n",
    "                metrics=['accuracy'])\n",
    "  \n",
    "  return model\n",
    "\n",
    "# create the model\n",
    "model = KerasClassifier(build_fn=create_model, epochs=13, verbose=0)\n",
    "\n",
    "# define the grid search parameters\n",
    "filters = [10, 20, 30, 40, 50]\n",
    "param_grid = dict(filters=filters)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3, verbose=10)\n",
    "grid_result = grid.fit(train_xx, train_yy)\n",
    "\n",
    "summarize_results(grid_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_hOp23hM0t-e"
   },
   "source": [
    "Neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 350
    },
    "colab_type": "code",
    "id": "ryeOAaF20dL2",
    "outputId": "90c3b64e-e845-4ebf-af06-410c8c094c09"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 7 candidates, totalling 21 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    7.8s\n",
      "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:   14.6s\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:   41.5s\n",
      "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done  21 out of  21 | elapsed:  2.6min remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  21 out of  21 | elapsed:  2.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.046667 using {'neurons': 200}\n",
      "0.000000 (0.000000) with: {'neurons': 10}\n",
      "0.033333 (0.012472) with: {'neurons': 50}\n",
      "0.040000 (0.024495) with: {'neurons': 100}\n",
      "0.033333 (0.026247) with: {'neurons': 150}\n",
      "0.046667 (0.016997) with: {'neurons': 200}\n",
      "0.033333 (0.012472) with: {'neurons': 250}\n",
      "0.033333 (0.016997) with: {'neurons': 300}\n"
     ]
    }
   ],
   "source": [
    "def create_model(neurons):\n",
    "  \n",
    "  model = Sequential()\n",
    "  model.add(Conv2D(30, (2, 2), input_shape=(28,84,1)))\n",
    "  model.add(Activation('tanh'))\n",
    "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "  # the model so far outputs 3D feature maps (height, width, features)\n",
    "\n",
    "  model.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
    "  model.add(Dense(neurons, kernel_initializer='glorot_normal'))\n",
    "  model.add(Activation('tanh'))\n",
    "  model.add(Dropout(0.4))\n",
    "  model.add(Dense(255, kernel_initializer='glorot_normal'))\n",
    "  model.add(Activation('softmax'))\n",
    "\n",
    "  model.compile(loss='sparse_categorical_crossentropy',\n",
    "                optimizer='nadam',\n",
    "                metrics=['accuracy'])\n",
    "  \n",
    "  return model\n",
    "\n",
    "# create the model\n",
    "model = KerasClassifier(build_fn=create_model, epochs=13, verbose=0)\n",
    "\n",
    "# define the grid search parameters\n",
    "neurons = [10, 50, 100, 150, 200, 250, 300]\n",
    "param_grid = dict(neurons=neurons)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3, verbose=10)\n",
    "grid_result = grid.fit(train_xx, train_yy)\n",
    "\n",
    "summarize_results(grid_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JGtpAePY764c"
   },
   "source": [
    "##Final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 486
    },
    "colab_type": "code",
    "id": "I3B7X08M7b1C",
    "outputId": "abe522d7-fb60-4142-98ac-027b97e7c0f1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/13\n",
      "30000/30000 [==============================] - 74s 2ms/step - loss: 3.8738 - acc: 0.1202\n",
      "Epoch 2/13\n",
      "30000/30000 [==============================] - 73s 2ms/step - loss: 1.6170 - acc: 0.5159\n",
      "Epoch 3/13\n",
      "30000/30000 [==============================] - 72s 2ms/step - loss: 0.9794 - acc: 0.7031\n",
      "Epoch 4/13\n",
      "30000/30000 [==============================] - 71s 2ms/step - loss: 0.7328 - acc: 0.7794\n",
      "Epoch 5/13\n",
      "30000/30000 [==============================] - 72s 2ms/step - loss: 0.5941 - acc: 0.8158\n",
      "Epoch 6/13\n",
      "30000/30000 [==============================] - 73s 2ms/step - loss: 0.5134 - acc: 0.8377\n",
      "Epoch 7/13\n",
      "30000/30000 [==============================] - 72s 2ms/step - loss: 0.4466 - acc: 0.8593\n",
      "Epoch 8/13\n",
      "30000/30000 [==============================] - 72s 2ms/step - loss: 0.3941 - acc: 0.8768\n",
      "Epoch 9/13\n",
      "30000/30000 [==============================] - 72s 2ms/step - loss: 0.3640 - acc: 0.8843\n",
      "Epoch 10/13\n",
      "30000/30000 [==============================] - 72s 2ms/step - loss: 0.3377 - acc: 0.8922\n",
      "Epoch 11/13\n",
      "30000/30000 [==============================] - 72s 2ms/step - loss: 0.3058 - acc: 0.9013\n",
      "Epoch 12/13\n",
      "30000/30000 [==============================] - 72s 2ms/step - loss: 0.2872 - acc: 0.9058\n",
      "Epoch 13/13\n",
      "30000/30000 [==============================] - 72s 2ms/step - loss: 0.2769 - acc: 0.9097\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3398f3af98>"
      ]
     },
     "execution_count": 33,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(35, (3, 3), input_shape=(28,84,1)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(3, 3)))\n",
    "\n",
    "model.add(Conv2D(35, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(3, 3)))\n",
    "\n",
    "# the model so far outputs 3D feature maps (height, width, features)\n",
    "\n",
    "model.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
    "model.add(Dense(200, kernel_initializer='glorot_normal'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(200, kernel_initializer='glorot_normal'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(255, kernel_initializer='glorot_normal'))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='nadam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_x, train_y, epochs=13)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "obGWbTlh74Ok"
   },
   "source": [
    "##Testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "CIUCZ-2J73rd",
    "outputId": "1b0d6399-2bfb-433c-e73a-225107313219"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 1s 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.337388696372509, 0.904]"
      ]
     },
     "execution_count": 34,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_x, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NGqqOhW6jpIy"
   },
   "source": [
    "##Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "h93bhiHpjrri"
   },
   "source": [
    "After tunning some parameters(and also experimenting manually on some activation functions) the model above got and *0% score on the test dataset.The model was trained on a dataset consisting of 20000 samples.If we would use a bigger dataset/increase the number of convolutional layers the accuracy would increase and it would easily reach a ~98% accuracy.The model depens a lot on data because we have 255 classes as a result.\n",
    "An alternative would be to split the number or maybe to try to predict each digit,so the classes would go down to 10(0-9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LDdJzQ1UmZoy"
   },
   "source": [
    "#Adding numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dk6yzJioU3OU"
   },
   "source": [
    "##Generating the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E9pRoncJU5Ss"
   },
   "outputs": [],
   "source": [
    "generator = training_generator(30000)\n",
    "img, train_x, train_y = next(generator)\n",
    "\n",
    "generator = training_generator(1000)\n",
    "img, test_x, test_y = next(generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wj4fHfIxVLPp"
   },
   "outputs": [],
   "source": [
    "def encode_data(train):\n",
    "  \n",
    "  len = train.shape[0]\n",
    "  \n",
    "  X = np.zeros((len, 6, 10))\n",
    "  Y = np.zeros((len, 3, 10))\n",
    "\n",
    "  for i in range(len):\n",
    "    a = train[i][0]\n",
    "    b = train[i][1]\n",
    "    s = a + b\n",
    "    \n",
    "    #number to array\n",
    "    a = [int(i) for i in str(a)]\n",
    "    b = [int(i) for i in str(b)]\n",
    "    s = [int(i) for i in str(s)]\n",
    "    \n",
    "    #padding the array with zeros\n",
    "    a, b, s = pad_sequences([a, b, s], maxlen = 3)\n",
    "\n",
    "    cnt = 0 \n",
    "    for j in a:\n",
    "      X[i, cnt, j] = 1\n",
    "      cnt = cnt + 1\n",
    "      \n",
    "    for j in b:\n",
    "      X[i, cnt, j] = 1\n",
    "      cnt = cnt + 1\n",
    "      \n",
    "    cnt = 0\n",
    "    for j in s:\n",
    "      Y[i, cnt, j] = 1\n",
    "      cnt = cnt + 1\n",
    "\n",
    "  return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Uo3K32BlXO8s"
   },
   "outputs": [],
   "source": [
    "train_x, train_y = encode_data(train_x)\n",
    "test_x, test_y = encode_data(test_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nMt09IM3lREf"
   },
   "source": [
    "##Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ybPEziDWlSju"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "#encoder layer\n",
    "model.add(LSTM(100, input_shape=(6, 10)))\n",
    "\n",
    "#connect the encoder to the decoder\n",
    "model.add(RepeatVector(3))\n",
    "\n",
    "#decoder layer\n",
    "model.add(LSTM(100, return_sequences=True))\n",
    "\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 312
    },
    "colab_type": "code",
    "id": "0ZW4QSQY93ZY",
    "outputId": "8d1a097a-0215-4015-d2b4-79d1c0c60c73"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_9 (LSTM)                (None, 100)               44400     \n",
      "_________________________________________________________________\n",
      "repeat_vector_4 (RepeatVecto (None, 3, 100)            0         \n",
      "_________________________________________________________________\n",
      "lstm_10 (LSTM)               (None, 3, 100)            80400     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 3, 10)             1010      \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 3, 10)             0         \n",
      "=================================================================\n",
      "Total params: 125,810\n",
      "Trainable params: 125,810\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 729
    },
    "colab_type": "code",
    "id": "asOFdUoQmOUf",
    "outputId": "66481750-4312-4813-ec1d-411aff7efe34"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 17s 582us/step - loss: 1.8554 - acc: 0.2712\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 15s 506us/step - loss: 1.5297 - acc: 0.4149\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 15s 504us/step - loss: 1.2054 - acc: 0.5440\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 15s 502us/step - loss: 1.0881 - acc: 0.5869\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 15s 499us/step - loss: 1.0309 - acc: 0.6085\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 15s 502us/step - loss: 0.9978 - acc: 0.6187\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 15s 494us/step - loss: 0.9738 - acc: 0.6262\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 15s 499us/step - loss: 0.9342 - acc: 0.6437\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 15s 497us/step - loss: 0.8717 - acc: 0.6703\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 15s 502us/step - loss: 0.7437 - acc: 0.7210\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 16s 528us/step - loss: 0.5301 - acc: 0.8185\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 15s 516us/step - loss: 0.3667 - acc: 0.8925\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 15s 501us/step - loss: 0.2630 - acc: 0.9302\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 15s 504us/step - loss: 0.1982 - acc: 0.9478\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 15s 497us/step - loss: 0.1566 - acc: 0.9581\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 15s 501us/step - loss: 0.1270 - acc: 0.9655\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 15s 496us/step - loss: 0.1017 - acc: 0.9725\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 15s 500us/step - loss: 0.0919 - acc: 0.9732\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 15s 499us/step - loss: 0.0809 - acc: 0.9757\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 15s 499us/step - loss: 0.0831 - acc: 0.9735\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f339a9b74a8>"
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_x, train_y, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "PmxYDHSOy-UY",
    "outputId": "5b9f08fe-1964-46ae-b7e5-a55ba664fafd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 1s 715us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.09228774487972259, 0.9699999985694885]"
      ]
     },
     "execution_count": 19,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_x, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "g6ZDHKpYADHF"
   },
   "source": [
    "##Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jLrfXjoQAGT8"
   },
   "source": [
    "The model predicts very well the sums.We are getting a ~97% accuracy with a 30.000 dataset and 20 epochs.We could easily get a 100% accuracy by increasing the number of epochs/samples.\n",
    "The model uses 2 LSTMs:one encoder,one decoder.Between them we place a RepeatVector to adapt the output of the encoder in order to be accepted by the decoder(increasing the dimensionality).\n",
    "Finally we use a Dense layer for the output."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "2foprbfslANt",
    "srtWIsYYyAbe",
    "06vdX_PTlaUd",
    "w4ep8l51yQ89",
    "_WNr0w-4xhyG",
    "e0m7sm280w4B",
    "LDdJzQ1UmZoy"
   ],
   "name": "Untitled6.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
